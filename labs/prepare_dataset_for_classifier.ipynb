{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-12T13:15:48.430995958Z",
     "start_time": "2023-05-12T13:15:40.363379110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "861964d48c22484089dd7c1b3872d8c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phung/Projects/technology-design/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in /mnt/external-ssd/cache_dir. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "995d9042fcb94a8aaa4bd4488ff41d07"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66c1e31b4e3e4238b06cf020a2c62064"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d37211763eb947f9b023c9636a4d6c53"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "Subword indices of matching word tensor([[1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])\n",
      "Merged mask tensor([[1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\").to(device)\n",
    "\n",
    "def paraphrase(\n",
    "    question,\n",
    "    num_beams=5,\n",
    "    num_beam_groups=5,\n",
    "    num_return_sequences=5,\n",
    "    repetition_penalty=10.0,\n",
    "    diversity_penalty=3.0,\n",
    "    no_repeat_ngram_size=2,\n",
    "    temperature=0.7,\n",
    "    max_length=128\n",
    "):\n",
    "    input_ids = tokenizer(\n",
    "        f'paraphrase: {question}',\n",
    "        return_tensors=\"pt\", padding=\"longest\",\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "    ).to(device).input_ids\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids, temperature=temperature, repetition_penalty=repetition_penalty,\n",
    "        num_return_sequences=num_return_sequences, no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "        num_beams=num_beams, num_beam_groups=num_beam_groups,\n",
    "        max_length=max_length, diversity_penalty=diversity_penalty\n",
    "    )\n",
    "\n",
    "    res = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# text = 'What kind of support do you offer to your online students?'\n",
    "# print(paraphrase(text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T13:15:56.070785614Z",
     "start_time": "2023-05-12T13:15:48.435267560Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n"
     ]
    }
   ],
   "source": [
    "from utils import faqs\n",
    "\n",
    "# Load Swinburne and Monash FAQs\n",
    "# faq_data = faqs.get_swinburne_faqs() + faqs.get_monash_faqs() + faqs.get_rmit_faqs()\n",
    "faq_data = faqs.get_swinburne_faqs()\n",
    "# Filter out questions and answers that explicitly mention Monash or monash and RMIT or rmit\n",
    "# faq_data = [(q, a) for q, a in faq_data if \"monash\" not in q.lower() and \"rmit\" not in q.lower() and \"monash\" not in a.lower() and \"rmit\" not in a.lower()]\n",
    "print(len(faq_data))\n",
    "faq_dataset = [{\"question\": q, \"answer\": a} for q, a in faq_data]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T04:04:16.870545Z",
     "start_time": "2023-05-21T04:04:15.916495Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n"
     ]
    }
   ],
   "source": [
    "for question_answer in faq_dataset:\n",
    "    question_answer[\"questions_set\"] = paraphrase(question_answer[\"question\"])\n",
    "    question_answer[\"answers_set\"] = paraphrase(question_answer[\"answer\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T13:17:24.772568278Z",
     "start_time": "2023-05-12T13:17:22.019625389Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n",
      "{'question': 'What support can I expect?', 'answer': 'As a Swinburne Online student, you’ll have support for extended hours, seven days a week, with Student Advisors available to help with anything from tech support to research advice and dedicated online tutors in each of your units. Learn more about your support .', 'questions_set': ['What aid can I receive?', 'Which assistance will be given to me?', 'What help I can get?', 'What kind of assistance can I receive?', 'what support I will be given?'], 'answers_set': ['Swinburne Online students have access to Student Advisors who are available for extended hours, seven days a week, offering various services from tech support to research advice and dedicated online tutors in each unit. Learn more about this service.', 'Swinburne Online students can count on Student Advisors to provide 24-hour support, which includes online tutoring in every unit and technical guidance for students. Learn more about this service.', 'Swinburne Online students can count on Student Advisors to provide 24-hour support, which includes online tutoring in every unit and technical guidance for students.', 'Swinburne Online students can count on Student Advisors to provide 24-hour support, which includes online tutoring in every unit and technical guidance for students. Learn more about this service. They are available 24/7 throughout the year.', 'Swinburne Online students can count on Student Advisors to provide 24-hour support, which includes online tutoring in every unit and technical guidance for students. Learn more about this service. They are available 24/7 throughout the year. For more information, click here.']}\n"
     ]
    }
   ],
   "source": [
    "print(len(faq_dataset))\n",
    "print(faq_dataset[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T09:28:53.799336Z",
     "start_time": "2023-05-11T09:28:53.788084Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate CSV from the resulting dataset\n",
    "You can run this to see a sample of the generated data.\n",
    "The next script will generate the paraphrased dataset and save it to a CSV file named `swinburne_paraphrased_faq.csv`.\n",
    "I have added a column `base_pair` to indicate the original question-answer pair.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('questions_answers_swinburne_only.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['prompt', 'completion']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for question_answer in faq_dataset:\n",
    "        writer.writerow({\n",
    "            'prompt': question_answer[\"question\"],\n",
    "            'completion': question_answer[\"answer\"],\n",
    "        })\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T04:05:57.870228Z",
     "start_time": "2023-05-21T04:05:57.836911Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('questions_answers_swinburne_monash.csv', 'r') as read_obj, \\\n",
    "        open('questions_answers_swinburne_only_monash_new_for_openai.csv', 'w', newline='') as write_obj:\n",
    "    # select first 2 column in the read_obj and write to write_obj with different headers\n",
    "    csv_reader = csv.reader(read_obj)\n",
    "    csv_writer = csv.writer(write_obj)\n",
    "    csv_writer.writerow(['prompt', 'completion'])\n",
    "    # skip the header row\n",
    "    next(csv_reader)\n",
    "    for row in csv_reader:\n",
    "        # if row[2] is X then skip\n",
    "        if row[2] == 'X':\n",
    "            continue\n",
    "        csv_writer.writerow(row)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T13:21:52.506084Z",
     "start_time": "2023-05-28T13:21:52.463579Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
