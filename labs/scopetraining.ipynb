{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style = 'font-family:Monocraft'>Swinburne FAQ Chatbot Scope Detection Component</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h2 style='font-family:Monocraft'>Scope Training</h2>\n",
    "    randomly shuffles 4 question label datasets to include 90% in scope and 10% out of scope data, then loads pretrained model and continuously trains them on randomised datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 59/1620 [55:02<24:16:03, 55.97s/it]\n",
      "loading configuration file config.json from cache at /Users/justin/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /Users/justin/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
      "loading file tokenizer.json from cache at /Users/justin/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/justin/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/justin/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file ./faq_scope_detection/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"./faq_scope_detection\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ./faq_scope_detection/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at ./faq_scope_detection.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Answer, text, __index_level_0__. If Answer, text, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/Users/justin/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3192\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1995\n",
      "  Number of trainable parameters = 66955010\n",
      "  0%|          | 0/1995 [00:00<?, ?it/s]You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "  1%|          | 10/1995 [00:02<07:21,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5184, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/1995 [00:04<07:56,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3007, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 31/1995 [00:07<07:05,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4682, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 40/1995 [00:09<07:17,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 50/1995 [00:11<08:06,  3.99it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-50\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-50/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-50/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-50/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-50/special_tokens_map.json\n",
      "  3%|▎         | 60/1995 [00:15<07:53,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8041, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 70/1995 [00:17<07:26,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 80/1995 [00:19<07:03,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5348, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 90/1995 [00:22<07:14,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5529, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 100/1995 [00:24<07:01,  4.50it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-100\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-100/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-100/special_tokens_map.json\n",
      "  6%|▌         | 110/1995 [00:27<07:28,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.4e-06, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 120/1995 [00:30<06:57,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 130/1995 [00:32<07:35,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.2e-06, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 140/1995 [00:34<07:13,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2383, 'learning_rate': 5.600000000000001e-06, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 150/1995 [00:36<06:42,  4.59it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-150\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-150/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6e-06, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-150/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-150/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-150/special_tokens_map.json\n",
      "  8%|▊         | 160/1995 [00:40<07:49,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0931, 'learning_rate': 6.4000000000000006e-06, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 170/1995 [00:42<07:01,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.800000000000001e-06, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 181/1995 [00:44<06:43,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.2000000000000005e-06, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 190/1995 [00:47<07:04,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 200/1995 [00:49<07:25,  4.02it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-200\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-200/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1741, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-200/special_tokens_map.json\n",
      " 11%|█         | 210/1995 [00:52<06:44,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 220/1995 [00:55<06:45,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.8e-06, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 231/1995 [00:57<06:07,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.200000000000002e-06, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 240/1995 [00:59<06:13,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1895, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 250/1995 [01:01<06:29,  4.47it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-250\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-250/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0485, 'learning_rate': 1e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-250/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-250/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-250/special_tokens_map.json\n",
      " 13%|█▎        | 260/1995 [01:05<07:20,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.04e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 270/1995 [01:07<06:29,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2136, 'learning_rate': 1.0800000000000002e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 280/1995 [01:09<06:15,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.1200000000000001e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 290/1995 [01:12<06:20,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.16e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 300/1995 [01:14<07:22,  3.83it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-300\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-300/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.2e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-300/special_tokens_map.json\n",
      " 16%|█▌        | 310/1995 [01:17<06:54,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.2400000000000002e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 320/1995 [01:19<06:10,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.2800000000000001e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 330/1995 [01:22<06:32,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.3200000000000002e-05, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 340/1995 [01:24<05:58,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.3600000000000002e-05, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 350/1995 [01:26<05:59,  4.58it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-350\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-350/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-350/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-350/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-350/special_tokens_map.json\n",
      " 18%|█▊        | 360/1995 [01:30<06:23,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.055, 'learning_rate': 1.4400000000000001e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 370/1995 [01:32<06:37,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2133, 'learning_rate': 1.48e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 380/1995 [01:34<06:13,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0016, 'learning_rate': 1.5200000000000002e-05, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 390/1995 [01:37<06:35,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.5600000000000003e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 399/1995 [01:39<05:53,  4.52it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Answer, text, __index_level_0__. If Answer, text, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 355\n",
      "  Batch size = 8\n",
      "\n",
      " 20%|██        | 399/1995 [01:41<05:53,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.024276206269860268, 'eval_runtime': 2.1599, 'eval_samples_per_second': 164.361, 'eval_steps_per_second': 20.835, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 400/1995 [01:41<23:03,  1.15it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-400\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-400/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1921, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-400/special_tokens_map.json\n",
      " 21%|██        | 411/1995 [01:44<06:00,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0001, 'learning_rate': 1.64e-05, 'epoch': 1.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 421/1995 [01:46<05:29,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0002, 'learning_rate': 1.6800000000000002e-05, 'epoch': 1.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 430/1995 [01:49<06:02,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.72e-05, 'epoch': 1.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 440/1995 [01:51<05:58,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.76e-05, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 450/1995 [01:53<05:45,  4.48it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-450\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-450/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.8e-05, 'epoch': 1.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-450/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-450/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-450/special_tokens_map.json\n",
      " 23%|██▎       | 460/1995 [01:57<07:03,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.8400000000000003e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 470/1995 [01:59<06:28,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.88e-05, 'epoch': 1.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 480/1995 [02:02<05:41,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0577, 'learning_rate': 1.9200000000000003e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 490/1995 [02:04<06:37,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.9600000000000002e-05, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 500/1995 [02:07<05:46,  4.32it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-500\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 1.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-500/special_tokens_map.json\n",
      " 26%|██▌       | 510/1995 [02:11<07:36,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0001, 'learning_rate': 1.9866220735785955e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 520/1995 [02:13<06:19,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0001, 'learning_rate': 1.973244147157191e-05, 'epoch': 1.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 530/1995 [02:15<05:36,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.9598662207357862e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 540/1995 [02:18<05:23,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.9464882943143815e-05, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 550/1995 [02:20<05:40,  4.25it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-550\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-550/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.933110367892977e-05, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-550/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-550/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-550/special_tokens_map.json\n",
      " 28%|██▊       | 560/1995 [02:23<06:04,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.9197324414715722e-05, 'epoch': 1.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 570/1995 [02:26<05:25,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.9063545150501676e-05, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 581/1995 [02:28<05:10,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.892976588628763e-05, 'epoch': 1.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 590/1995 [02:30<04:58,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0435, 'learning_rate': 1.879598662207358e-05, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 600/1995 [02:32<04:51,  4.78it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-600\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-600/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.8662207357859533e-05, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-600/special_tokens_map.json\n",
      " 31%|███       | 611/1995 [02:35<04:56,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.8528428093645486e-05, 'epoch': 1.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 620/1995 [02:37<05:03,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.008, 'learning_rate': 1.839464882943144e-05, 'epoch': 1.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 630/1995 [02:40<05:45,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.8260869565217393e-05, 'epoch': 1.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 641/1995 [02:42<04:43,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.8127090301003347e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 650/1995 [02:44<04:59,  4.48it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-650\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-650/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.7993311036789297e-05, 'epoch': 1.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-650/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-650/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-650/special_tokens_map.json\n",
      " 33%|███▎      | 660/1995 [02:47<05:45,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.785953177257525e-05, 'epoch': 1.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 670/1995 [02:50<05:18,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0711, 'learning_rate': 1.7725752508361204e-05, 'epoch': 1.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 680/1995 [02:52<05:28,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0001, 'learning_rate': 1.7591973244147157e-05, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 690/1995 [02:55<05:24,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.745819397993311e-05, 'epoch': 1.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 700/1995 [02:57<05:20,  4.05it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-700\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-700/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.7324414715719064e-05, 'epoch': 1.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-700/special_tokens_map.json\n",
      " 36%|███▌      | 710/1995 [03:00<05:22,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.7190635451505017e-05, 'epoch': 1.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 720/1995 [03:02<04:41,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.705685618729097e-05, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 730/1995 [03:05<05:01,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.6923076923076924e-05, 'epoch': 1.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 740/1995 [03:07<04:38,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.6789297658862878e-05, 'epoch': 1.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 750/1995 [03:09<04:53,  4.24it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-750\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-750/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.665551839464883e-05, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-750/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-750/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-750/special_tokens_map.json\n",
      " 38%|███▊      | 760/1995 [03:13<05:01,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0571, 'learning_rate': 1.6521739130434785e-05, 'epoch': 1.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 770/1995 [03:15<04:42,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.6387959866220738e-05, 'epoch': 1.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 780/1995 [03:17<05:00,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.625418060200669e-05, 'epoch': 1.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 790/1995 [03:20<04:42,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0002, 'learning_rate': 1.6120401337792645e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 798/1995 [03:22<05:03,  3.95it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Answer, text, __index_level_0__. If Answer, text, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 355\n",
      "  Batch size = 8\n",
      "\n",
      " 40%|████      | 798/1995 [03:25<05:03,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2223084411289165e-07, 'eval_runtime': 2.7466, 'eval_samples_per_second': 129.252, 'eval_steps_per_second': 16.384, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 800/1995 [03:25<17:26,  1.14it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-800\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-800/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.59866220735786e-05, 'epoch': 2.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-800/special_tokens_map.json\n",
      " 41%|████      | 810/1995 [03:29<05:12,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.5852842809364552e-05, 'epoch': 2.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 820/1995 [03:31<04:46,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.5719063545150505e-05, 'epoch': 2.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 830/1995 [03:33<04:14,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.5585284280936455e-05, 'epoch': 2.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 840/1995 [03:36<04:20,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.545150501672241e-05, 'epoch': 2.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 850/1995 [03:38<04:48,  3.97it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-850\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-850/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.5317725752508362e-05, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-850/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-850/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-850/special_tokens_map.json\n",
      " 43%|████▎     | 860/1995 [03:41<04:51,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.5183946488294317e-05, 'epoch': 2.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 870/1995 [03:44<04:27,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.5050167224080269e-05, 'epoch': 2.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 880/1995 [03:46<04:38,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4916387959866221e-05, 'epoch': 2.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 890/1995 [03:49<04:29,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4782608695652174e-05, 'epoch': 2.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 900/1995 [03:51<04:29,  4.06it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-900\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-900/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4648829431438128e-05, 'epoch': 2.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-900/special_tokens_map.json\n",
      " 46%|████▌     | 910/1995 [03:55<04:32,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4515050167224081e-05, 'epoch': 2.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 920/1995 [03:57<04:03,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4381270903010035e-05, 'epoch': 2.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 930/1995 [03:59<03:54,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4247491638795986e-05, 'epoch': 2.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 941/1995 [04:02<03:54,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.411371237458194e-05, 'epoch': 2.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 950/1995 [04:04<03:52,  4.50it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-950\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-950/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.3979933110367893e-05, 'epoch': 2.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-950/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-950/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-950/special_tokens_map.json\n",
      " 48%|████▊     | 960/1995 [04:07<04:04,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.3846153846153847e-05, 'epoch': 2.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 970/1995 [04:09<03:44,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.37123745819398e-05, 'epoch': 2.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 980/1995 [04:11<04:03,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.3578595317725754e-05, 'epoch': 2.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 990/1995 [04:14<03:44,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.3444816053511707e-05, 'epoch': 2.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1000/1995 [04:16<03:38,  4.54it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1000\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.331103678929766e-05, 'epoch': 2.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1000/special_tokens_map.json\n",
      " 51%|█████     | 1010/1995 [04:19<03:40,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.3177257525083614e-05, 'epoch': 2.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1021/1995 [04:22<03:41,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.3043478260869566e-05, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1030/1995 [04:24<03:44,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.290969899665552e-05, 'epoch': 2.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1040/1995 [04:26<03:24,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.2775919732441473e-05, 'epoch': 2.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1050/1995 [04:28<04:05,  3.86it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1050\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1050/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.2642140468227426e-05, 'epoch': 2.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1050/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1050/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1050/special_tokens_map.json\n",
      " 53%|█████▎    | 1060/1995 [04:32<03:45,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.250836120401338e-05, 'epoch': 2.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 1070/1995 [04:34<03:37,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.2374581939799333e-05, 'epoch': 2.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 1080/1995 [04:36<03:32,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.2240802675585286e-05, 'epoch': 2.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 1090/1995 [04:39<04:00,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.210702341137124e-05, 'epoch': 2.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 1100/1995 [04:41<03:41,  4.05it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1100\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1100/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.1973244147157193e-05, 'epoch': 2.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1100/special_tokens_map.json\n",
      " 56%|█████▌    | 1110/1995 [04:45<04:03,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.1839464882943145e-05, 'epoch': 2.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1120/1995 [04:47<03:34,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.1705685618729099e-05, 'epoch': 2.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1130/1995 [04:50<03:24,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.157190635451505e-05, 'epoch': 2.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1140/1995 [04:52<03:05,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.1438127090301004e-05, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1150/1995 [04:54<03:31,  4.00it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1150\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1150/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.1304347826086957e-05, 'epoch': 2.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1150/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1150/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1150/special_tokens_map.json\n",
      " 58%|█████▊    | 1160/1995 [04:58<03:28,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.117056856187291e-05, 'epoch': 2.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 1170/1995 [05:00<03:09,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.1036789297658862e-05, 'epoch': 2.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 1180/1995 [05:02<03:08,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.0903010033444816e-05, 'epoch': 2.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 1190/1995 [05:05<03:02,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.076923076923077e-05, 'epoch': 2.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1197/1995 [05:06<03:34,  3.72it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Answer, text, __index_level_0__. If Answer, text, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 355\n",
      "  Batch size = 8\n",
      "\n",
      " 60%|██████    | 1197/1995 [05:09<03:34,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3700557133233815e-07, 'eval_runtime': 2.3494, 'eval_samples_per_second': 151.104, 'eval_steps_per_second': 19.154, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1200/1995 [05:09<07:53,  1.68it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1200\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1200/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.0635451505016723e-05, 'epoch': 3.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1200/special_tokens_map.json\n",
      " 61%|██████    | 1210/1995 [05:13<03:09,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.0501672240802676e-05, 'epoch': 3.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1220/1995 [05:15<02:55,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.036789297658863e-05, 'epoch': 3.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1230/1995 [05:17<03:03,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.0234113712374583e-05, 'epoch': 3.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1240/1995 [05:20<02:51,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.0100334448160537e-05, 'epoch': 3.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1250/1995 [05:22<03:01,  4.11it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1250\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1250/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.966555183946488e-06, 'epoch': 3.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1250/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1250/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1250/special_tokens_map.json\n",
      " 63%|██████▎   | 1260/1995 [05:25<03:07,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.832775919732442e-06, 'epoch': 3.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 1270/1995 [05:28<02:44,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.698996655518395e-06, 'epoch': 3.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 1280/1995 [05:30<02:36,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.565217391304349e-06, 'epoch': 3.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 1290/1995 [05:32<03:01,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.431438127090302e-06, 'epoch': 3.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1300/1995 [05:35<02:51,  4.06it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1300\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1300/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.297658862876256e-06, 'epoch': 3.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1300/special_tokens_map.json\n",
      " 66%|██████▌   | 1310/1995 [05:38<03:01,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.163879598662207e-06, 'epoch': 3.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1320/1995 [05:41<02:44,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.03010033444816e-06, 'epoch': 3.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1330/1995 [05:43<02:44,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.896321070234114e-06, 'epoch': 3.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1340/1995 [05:46<02:39,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.762541806020068e-06, 'epoch': 3.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1350/1995 [05:48<02:41,  3.98it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1350\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1350/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.628762541806021e-06, 'epoch': 3.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1350/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1350/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1350/special_tokens_map.json\n",
      " 68%|██████▊   | 1360/1995 [05:52<02:48,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.494983277591975e-06, 'epoch': 3.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 1370/1995 [05:54<02:21,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.361204013377926e-06, 'epoch': 3.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 1380/1995 [05:56<02:30,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.22742474916388e-06, 'epoch': 3.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 1390/1995 [05:59<02:35,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.093645484949833e-06, 'epoch': 3.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1400/1995 [06:01<02:27,  4.03it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1400\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1400/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.959866220735787e-06, 'epoch': 3.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1400/special_tokens_map.json\n",
      " 71%|███████   | 1410/1995 [06:04<02:13,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.82608695652174e-06, 'epoch': 3.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 1420/1995 [06:07<02:08,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.692307692307694e-06, 'epoch': 3.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1430/1995 [06:09<02:06,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.558528428093647e-06, 'epoch': 3.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1440/1995 [06:11<02:09,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.424749163879599e-06, 'epoch': 3.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1450/1995 [06:13<02:05,  4.33it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1450\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1450/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.290969899665552e-06, 'epoch': 3.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1450/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1450/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1450/special_tokens_map.json\n",
      " 73%|███████▎  | 1460/1995 [06:17<02:29,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.157190635451506e-06, 'epoch': 3.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 1470/1995 [06:19<02:06,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.023411371237458e-06, 'epoch': 3.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1480/1995 [06:22<02:12,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.889632107023412e-06, 'epoch': 3.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 1490/1995 [06:24<02:05,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.755852842809365e-06, 'epoch': 3.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1500/1995 [06:27<02:03,  4.02it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1500\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.622073578595319e-06, 'epoch': 3.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1500/special_tokens_map.json\n",
      " 76%|███████▌  | 1510/1995 [06:30<01:58,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.488294314381271e-06, 'epoch': 3.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1521/1995 [06:32<01:38,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.354515050167225e-06, 'epoch': 3.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1530/1995 [06:35<02:06,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.220735785953178e-06, 'epoch': 3.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1541/1995 [06:37<01:40,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.086956521739132e-06, 'epoch': 3.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1550/1995 [06:39<01:48,  4.09it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1550\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1550/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.953177257525084e-06, 'epoch': 3.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1550/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1550/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1550/special_tokens_map.json\n",
      " 78%|███████▊  | 1560/1995 [06:43<01:54,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.819397993311037e-06, 'epoch': 3.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 1570/1995 [06:45<01:34,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.68561872909699e-06, 'epoch': 3.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 1580/1995 [06:48<01:47,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.551839464882943e-06, 'epoch': 3.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 1590/1995 [06:50<01:37,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.418060200668896e-06, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1596/1995 [06:52<01:42,  3.90it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Answer, text, __index_level_0__. If Answer, text, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 355\n",
      "  Batch size = 8\n",
      "\n",
      " 80%|████████  | 1596/1995 [06:54<01:42,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2424537487731868e-07, 'eval_runtime': 2.2893, 'eval_samples_per_second': 155.067, 'eval_steps_per_second': 19.656, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1600/1995 [06:55<03:02,  2.17it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1600\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1600/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.28428093645485e-06, 'epoch': 4.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1600/special_tokens_map.json\n",
      " 81%|████████  | 1610/1995 [06:58<01:41,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.150501672240803e-06, 'epoch': 4.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 1620/1995 [07:01<01:25,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.016722408026757e-06, 'epoch': 4.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1630/1995 [07:03<01:16,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.882943143812709e-06, 'epoch': 4.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1641/1995 [07:06<01:30,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.749163879598663e-06, 'epoch': 4.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1650/1995 [07:08<01:20,  4.27it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1650\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1650/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.615384615384616e-06, 'epoch': 4.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1650/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1650/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1650/special_tokens_map.json\n",
      " 83%|████████▎ | 1660/1995 [07:11<01:27,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.481605351170569e-06, 'epoch': 4.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 1670/1995 [07:14<01:19,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.347826086956522e-06, 'epoch': 4.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1680/1995 [07:17<01:14,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.214046822742475e-06, 'epoch': 4.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1690/1995 [07:19<01:20,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.080267558528428e-06, 'epoch': 4.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1700/1995 [07:22<01:07,  4.38it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1700\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1700/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.946488294314382e-06, 'epoch': 4.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1700/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1700/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1700/special_tokens_map.json\n",
      " 86%|████████▌ | 1710/1995 [07:25<01:06,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.812709030100335e-06, 'epoch': 4.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1720/1995 [07:27<01:04,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0001, 'learning_rate': 3.6789297658862878e-06, 'epoch': 4.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1730/1995 [07:29<01:01,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.5451505016722408e-06, 'epoch': 4.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1740/1995 [07:32<00:58,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.4113712374581942e-06, 'epoch': 4.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1750/1995 [07:34<00:53,  4.57it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1750\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1750/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.2775919732441473e-06, 'epoch': 4.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1750/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1750/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1750/special_tokens_map.json\n",
      " 88%|████████▊ | 1760/1995 [07:37<00:57,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.1438127090301007e-06, 'epoch': 4.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 1770/1995 [07:40<00:51,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.010033444816054e-06, 'epoch': 4.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1780/1995 [07:42<00:48,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.8762541806020068e-06, 'epoch': 4.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 1790/1995 [07:44<00:44,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.74247491638796e-06, 'epoch': 4.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1800/1995 [07:46<00:42,  4.60it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1800\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1800/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.6086956521739132e-06, 'epoch': 4.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1800/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1800/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1800/special_tokens_map.json\n",
      " 91%|█████████ | 1810/1995 [07:49<00:45,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.4749163879598663e-06, 'epoch': 4.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1820/1995 [07:52<00:39,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.3411371237458197e-06, 'epoch': 4.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1831/1995 [07:54<00:39,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.2073578595317727e-06, 'epoch': 4.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1840/1995 [07:56<00:37,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.0735785953177258e-06, 'epoch': 4.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1850/1995 [07:59<00:34,  4.26it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1850\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1850/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.9397993311036792e-06, 'epoch': 4.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1850/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1850/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1850/special_tokens_map.json\n",
      " 93%|█████████▎| 1860/1995 [08:02<00:33,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.8060200668896322e-06, 'epoch': 4.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 1870/1995 [08:04<00:27,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.6722408026755855e-06, 'epoch': 4.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1880/1995 [08:07<00:26,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.5384615384615387e-06, 'epoch': 4.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 1890/1995 [08:09<00:24,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4046822742474917e-06, 'epoch': 4.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1900/1995 [08:12<00:22,  4.16it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1900\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1900/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.270903010033445e-06, 'epoch': 4.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1900/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1900/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1900/special_tokens_map.json\n",
      " 96%|█████████▌| 1910/1995 [08:15<00:24,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.137123745819398e-06, 'epoch': 4.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1920/1995 [08:17<00:16,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.0033444816053512e-06, 'epoch': 4.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1930/1995 [08:20<00:15,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.695652173913044e-07, 'epoch': 4.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1940/1995 [08:22<00:13,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.357859531772576e-07, 'epoch': 4.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1950/1995 [08:24<00:10,  4.20it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1950\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1950/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.020066889632107e-07, 'epoch': 4.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1950/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1950/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1950/special_tokens_map.json\n",
      " 98%|█████████▊| 1960/1995 [08:29<00:09,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.682274247491639e-07, 'epoch': 4.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 1970/1995 [08:31<00:06,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.3444816053511706e-07, 'epoch': 4.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1980/1995 [08:34<00:04,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.0066889632107025e-07, 'epoch': 4.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1990/1995 [08:36<00:01,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.688963210702342e-08, 'epoch': 4.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1995/1995 [08:37<00:00,  4.06it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Answer, text, __index_level_0__. If Answer, text, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 355\n",
      "  Batch size = 8\n",
      "\n",
      "100%|██████████| 1995/1995 [08:40<00:00,  4.06it/s]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 1995/1995 [08:40<00:00,  3.83it/s]\n",
      "Saving model checkpoint to ./faq_scope_detection\n",
      "Configuration saved in ./faq_scope_detection/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.305649963815995e-08, 'eval_runtime': 2.4494, 'eval_samples_per_second': 144.933, 'eval_steps_per_second': 18.372, 'epoch': 5.0}\n",
      "{'train_runtime': 520.3637, 'train_samples_per_second': 30.671, 'train_steps_per_second': 3.834, 'train_loss': 0.024244236803733884, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/special_tokens_map.json\n",
      "loading configuration file config.json from cache at /Users/justin/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /Users/justin/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
      "loading file tokenizer.json from cache at /Users/justin/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/justin/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/justin/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file ./faq_scope_detection/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"./faq_scope_detection\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ./faq_scope_detection/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at ./faq_scope_detection.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Answer, text, __index_level_0__. If Answer, text, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/Users/justin/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3192\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1995\n",
      "  Number of trainable parameters = 66955010\n",
      "  0%|          | 0/1995 [00:00<?, ?it/s]You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "  1%|          | 10/1995 [00:02<07:41,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/1995 [00:04<07:58,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 31/1995 [00:07<06:47,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 40/1995 [00:09<07:20,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0002, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 50/1995 [00:11<08:15,  3.93it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-50\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-50/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-50/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-50/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-50/special_tokens_map.json\n",
      "  3%|▎         | 60/1995 [00:15<08:04,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 70/1995 [00:17<07:23,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 80/1995 [00:19<06:56,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 90/1995 [00:22<07:12,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 100/1995 [00:24<07:01,  4.49it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-100\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-100/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-100/special_tokens_map.json\n",
      "  6%|▌         | 111/1995 [00:27<07:06,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.4e-06, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 121/1995 [00:30<06:36,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 130/1995 [00:32<07:06,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.2e-06, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 140/1995 [00:34<07:23,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.600000000000001e-06, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 150/1995 [00:36<06:31,  4.72it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-150\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-150/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6e-06, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-150/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-150/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-150/special_tokens_map.json\n",
      "  8%|▊         | 160/1995 [00:39<07:46,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.4000000000000006e-06, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 170/1995 [00:42<07:15,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.800000000000001e-06, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 180/1995 [00:44<07:14,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.2000000000000005e-06, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 190/1995 [00:47<07:08,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 200/1995 [00:49<07:42,  3.88it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-200\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-200/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-200/special_tokens_map.json\n",
      " 11%|█         | 210/1995 [00:52<06:59,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 220/1995 [00:55<06:48,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.8e-06, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 231/1995 [00:57<06:07,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.200000000000002e-06, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 241/1995 [00:59<06:05,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 250/1995 [01:01<06:14,  4.66it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-250\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-250/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-250/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-250/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-250/special_tokens_map.json\n",
      " 13%|█▎        | 260/1995 [01:04<06:55,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.04e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 270/1995 [01:07<06:23,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.0800000000000002e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 280/1995 [01:09<06:19,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.1200000000000001e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 290/1995 [01:11<06:13,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.16e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 300/1995 [01:14<07:29,  3.77it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-300\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-300/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.2e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-300/special_tokens_map.json\n",
      " 16%|█▌        | 310/1995 [01:17<07:07,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.2400000000000002e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 320/1995 [01:19<06:15,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.2800000000000001e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 330/1995 [01:22<06:40,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.3200000000000002e-05, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 340/1995 [01:24<06:16,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.3600000000000002e-05, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 350/1995 [01:26<05:47,  4.73it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-350\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-350/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-350/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-350/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-350/special_tokens_map.json\n",
      " 18%|█▊        | 360/1995 [01:29<06:07,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4400000000000001e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 370/1995 [01:32<06:39,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.48e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 380/1995 [01:34<06:10,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.5200000000000002e-05, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 390/1995 [01:36<06:20,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.5600000000000003e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 399/1995 [01:38<05:50,  4.56it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Answer, text, __index_level_0__. If Answer, text, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 355\n",
      "  Batch size = 8\n",
      "\n",
      " 20%|██        | 399/1995 [01:40<05:50,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.21628457808265e-08, 'eval_runtime': 2.0816, 'eval_samples_per_second': 170.544, 'eval_steps_per_second': 21.618, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 400/1995 [01:41<22:23,  1.19it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-400\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-400/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-400/special_tokens_map.json\n",
      " 21%|██        | 410/1995 [01:44<06:25,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.64e-05, 'epoch': 1.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 420/1995 [01:46<05:55,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.6800000000000002e-05, 'epoch': 1.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 430/1995 [01:48<06:02,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.72e-05, 'epoch': 1.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 440/1995 [01:50<05:56,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.76e-05, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 450/1995 [01:53<05:55,  4.34it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-450\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-450/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.8e-05, 'epoch': 1.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-450/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-450/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-450/special_tokens_map.json\n",
      " 23%|██▎       | 460/1995 [01:56<07:05,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.8400000000000003e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 470/1995 [01:59<07:07,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.88e-05, 'epoch': 1.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 480/1995 [02:01<06:07,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.9200000000000003e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 490/1995 [02:04<05:56,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.9600000000000002e-05, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 500/1995 [02:06<06:16,  3.97it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-500\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 1.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-500/special_tokens_map.json\n",
      " 26%|██▌       | 510/1995 [02:09<05:48,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.9866220735785955e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 520/1995 [02:12<06:41,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.973244147157191e-05, 'epoch': 1.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 530/1995 [02:14<05:22,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.9598662207357862e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 540/1995 [02:16<05:13,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.9464882943143815e-05, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 550/1995 [02:19<05:46,  4.17it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-550\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-550/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.933110367892977e-05, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-550/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-550/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-550/special_tokens_map.json\n",
      " 28%|██▊       | 560/1995 [02:22<06:15,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.9197324414715722e-05, 'epoch': 1.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 570/1995 [02:24<05:24,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.9063545150501676e-05, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 580/1995 [02:27<05:38,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.892976588628763e-05, 'epoch': 1.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 590/1995 [02:29<05:25,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.879598662207358e-05, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 600/1995 [02:31<05:27,  4.26it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-600\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-600/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.8662207357859533e-05, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-600/special_tokens_map.json\n",
      " 31%|███       | 610/1995 [02:35<06:12,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.8528428093645486e-05, 'epoch': 1.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 620/1995 [02:38<05:34,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.839464882943144e-05, 'epoch': 1.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 630/1995 [02:40<06:29,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.8260869565217393e-05, 'epoch': 1.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 640/1995 [02:43<05:18,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.8127090301003347e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 650/1995 [02:45<05:25,  4.13it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-650\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-650/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.7993311036789297e-05, 'epoch': 1.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-650/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-650/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-650/special_tokens_map.json\n",
      " 33%|███▎      | 660/1995 [02:49<06:11,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.785953177257525e-05, 'epoch': 1.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 670/1995 [02:51<05:33,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.7725752508361204e-05, 'epoch': 1.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 680/1995 [02:54<05:58,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.7591973244147157e-05, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 690/1995 [02:56<05:57,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.745819397993311e-05, 'epoch': 1.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 700/1995 [02:59<05:37,  3.84it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-700\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-700/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.7324414715719064e-05, 'epoch': 1.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-700/special_tokens_map.json\n",
      " 36%|███▌      | 710/1995 [03:02<05:48,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.7190635451505017e-05, 'epoch': 1.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 720/1995 [03:05<05:12,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.705685618729097e-05, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 730/1995 [03:07<05:30,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.6923076923076924e-05, 'epoch': 1.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 740/1995 [03:10<05:04,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.6789297658862878e-05, 'epoch': 1.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 750/1995 [03:12<05:25,  3.83it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-750\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-750/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.665551839464883e-05, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-750/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-750/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-750/special_tokens_map.json\n",
      " 38%|███▊      | 760/1995 [03:16<05:26,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.6521739130434785e-05, 'epoch': 1.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 770/1995 [03:18<04:59,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.6387959866220738e-05, 'epoch': 1.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 780/1995 [03:21<05:20,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.625418060200669e-05, 'epoch': 1.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 790/1995 [03:23<04:55,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.6120401337792645e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 798/1995 [03:25<04:53,  4.08it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Answer, text, __index_level_0__. If Answer, text, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 355\n",
      "  Batch size = 8\n",
      "\n",
      " 40%|████      | 798/1995 [03:28<04:53,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.365409811413201e-09, 'eval_runtime': 2.3372, 'eval_samples_per_second': 151.892, 'eval_steps_per_second': 19.254, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 800/1995 [03:28<14:52,  1.34it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-800\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-800/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.59866220735786e-05, 'epoch': 2.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-800/special_tokens_map.json\n",
      " 41%|████      | 810/1995 [03:32<05:16,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.5852842809364552e-05, 'epoch': 2.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 820/1995 [03:34<05:05,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.5719063545150505e-05, 'epoch': 2.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 830/1995 [03:37<04:34,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.5585284280936455e-05, 'epoch': 2.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 840/1995 [03:39<04:44,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.545150501672241e-05, 'epoch': 2.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 850/1995 [03:42<05:08,  3.72it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-850\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-850/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.5317725752508362e-05, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-850/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-850/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-850/special_tokens_map.json\n",
      " 43%|████▎     | 860/1995 [03:46<05:20,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.5183946488294317e-05, 'epoch': 2.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 870/1995 [03:48<04:47,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.5050167224080269e-05, 'epoch': 2.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 880/1995 [03:51<04:51,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4916387959866221e-05, 'epoch': 2.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 890/1995 [03:54<04:47,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4782608695652174e-05, 'epoch': 2.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 900/1995 [03:56<04:58,  3.66it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-900\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-900/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4648829431438128e-05, 'epoch': 2.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-900/special_tokens_map.json\n",
      " 46%|████▌     | 910/1995 [04:00<04:51,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4515050167224081e-05, 'epoch': 2.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 920/1995 [04:02<04:19,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4381270903010035e-05, 'epoch': 2.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 930/1995 [04:05<04:14,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4247491638795986e-05, 'epoch': 2.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 940/1995 [04:07<04:31,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.411371237458194e-05, 'epoch': 2.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 950/1995 [04:10<04:15,  4.09it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-950\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-950/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.3979933110367893e-05, 'epoch': 2.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-950/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-950/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-950/special_tokens_map.json\n",
      " 48%|████▊     | 960/1995 [04:13<04:24,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.3846153846153847e-05, 'epoch': 2.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 970/1995 [04:16<04:17,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.37123745819398e-05, 'epoch': 2.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 980/1995 [04:18<04:23,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.3578595317725754e-05, 'epoch': 2.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 990/1995 [04:21<03:58,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.3444816053511707e-05, 'epoch': 2.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1000/1995 [04:23<03:50,  4.31it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1000\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.331103678929766e-05, 'epoch': 2.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1000/special_tokens_map.json\n",
      " 51%|█████     | 1010/1995 [04:26<03:58,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.3177257525083614e-05, 'epoch': 2.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1020/1995 [04:29<04:15,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.3043478260869566e-05, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1030/1995 [04:31<04:07,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.290969899665552e-05, 'epoch': 2.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1040/1995 [04:34<03:45,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.2775919732441473e-05, 'epoch': 2.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1050/1995 [04:37<04:30,  3.50it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1050\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1050/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.2642140468227426e-05, 'epoch': 2.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1050/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1050/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1050/special_tokens_map.json\n",
      " 53%|█████▎    | 1060/1995 [04:40<03:53,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.250836120401338e-05, 'epoch': 2.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 1070/1995 [04:42<03:43,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.2374581939799333e-05, 'epoch': 2.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 1080/1995 [04:45<03:39,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.2240802675585286e-05, 'epoch': 2.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 1090/1995 [04:47<03:59,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.210702341137124e-05, 'epoch': 2.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 1100/1995 [04:50<03:49,  3.90it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1100\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1100/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.1973244147157193e-05, 'epoch': 2.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1100/special_tokens_map.json\n",
      " 56%|█████▌    | 1110/1995 [04:53<03:57,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.1839464882943145e-05, 'epoch': 2.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1120/1995 [04:56<03:53,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.1705685618729099e-05, 'epoch': 2.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1130/1995 [04:59<03:43,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.157190635451505e-05, 'epoch': 2.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1140/1995 [05:01<03:29,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.1438127090301004e-05, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1150/1995 [05:04<03:59,  3.53it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1150\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1150/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.1304347826086957e-05, 'epoch': 2.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1150/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1150/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1150/special_tokens_map.json\n",
      " 58%|█████▊    | 1160/1995 [05:08<03:52,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.117056856187291e-05, 'epoch': 2.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 1170/1995 [05:10<03:27,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.1036789297658862e-05, 'epoch': 2.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 1180/1995 [05:13<03:29,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.0903010033444816e-05, 'epoch': 2.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 1190/1995 [05:15<03:10,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.076923076923077e-05, 'epoch': 2.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1197/1995 [05:17<03:43,  3.57it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Answer, text, __index_level_0__. If Answer, text, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 355\n",
      "  Batch size = 8\n",
      "\n",
      " 60%|██████    | 1197/1995 [05:20<03:43,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6790037138392222e-09, 'eval_runtime': 2.3793, 'eval_samples_per_second': 149.201, 'eval_steps_per_second': 18.913, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1200/1995 [05:20<08:07,  1.63it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1200\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1200/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.0635451505016723e-05, 'epoch': 3.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1200/special_tokens_map.json\n",
      " 61%|██████    | 1210/1995 [05:24<03:13,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.0501672240802676e-05, 'epoch': 3.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1220/1995 [05:26<02:59,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.036789297658863e-05, 'epoch': 3.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1230/1995 [05:29<03:12,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.0234113712374583e-05, 'epoch': 3.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1240/1995 [05:31<03:01,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.0100334448160537e-05, 'epoch': 3.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1250/1995 [05:34<03:12,  3.88it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1250\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1250/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.966555183946488e-06, 'epoch': 3.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1250/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1250/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1250/special_tokens_map.json\n",
      " 63%|██████▎   | 1260/1995 [05:37<03:21,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.832775919732442e-06, 'epoch': 3.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 1270/1995 [05:40<02:51,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.698996655518395e-06, 'epoch': 3.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 1280/1995 [05:42<02:44,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.565217391304349e-06, 'epoch': 3.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 1290/1995 [05:44<03:00,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.431438127090302e-06, 'epoch': 3.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1300/1995 [05:47<02:54,  3.98it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1300\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1300/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.297658862876256e-06, 'epoch': 3.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1300/special_tokens_map.json\n",
      " 66%|██████▌   | 1310/1995 [05:50<03:06,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.163879598662207e-06, 'epoch': 3.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1320/1995 [05:53<02:44,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 9.03010033444816e-06, 'epoch': 3.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1330/1995 [05:55<02:47,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.896321070234114e-06, 'epoch': 3.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1340/1995 [05:58<02:47,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.762541806020068e-06, 'epoch': 3.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1350/1995 [06:01<02:49,  3.81it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1350\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1350/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.628762541806021e-06, 'epoch': 3.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1350/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1350/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1350/special_tokens_map.json\n",
      " 68%|██████▊   | 1360/1995 [06:04<02:41,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.494983277591975e-06, 'epoch': 3.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 1370/1995 [06:06<02:26,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.361204013377926e-06, 'epoch': 3.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 1380/1995 [06:09<02:28,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.22742474916388e-06, 'epoch': 3.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 1390/1995 [06:11<02:38,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.093645484949833e-06, 'epoch': 3.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1400/1995 [06:14<02:31,  3.94it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1400\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1400/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.959866220735787e-06, 'epoch': 3.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1400/special_tokens_map.json\n",
      " 71%|███████   | 1410/1995 [06:17<02:28,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.82608695652174e-06, 'epoch': 3.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 1420/1995 [06:20<02:19,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.692307692307694e-06, 'epoch': 3.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1430/1995 [06:22<02:13,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.558528428093647e-06, 'epoch': 3.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1440/1995 [06:25<02:11,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.424749163879599e-06, 'epoch': 3.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1450/1995 [06:27<02:07,  4.28it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1450\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1450/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.290969899665552e-06, 'epoch': 3.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1450/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1450/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1450/special_tokens_map.json\n",
      " 73%|███████▎  | 1460/1995 [06:31<02:30,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.157190635451506e-06, 'epoch': 3.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 1470/1995 [06:33<02:06,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.023411371237458e-06, 'epoch': 3.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1480/1995 [06:35<02:14,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.889632107023412e-06, 'epoch': 3.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 1490/1995 [06:38<02:09,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.755852842809365e-06, 'epoch': 3.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1500/1995 [06:41<02:11,  3.75it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1500\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.622073578595319e-06, 'epoch': 3.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1500/special_tokens_map.json\n",
      " 76%|███████▌  | 1510/1995 [06:44<02:07,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.488294314381271e-06, 'epoch': 3.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1520/1995 [06:46<01:49,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.354515050167225e-06, 'epoch': 3.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1530/1995 [06:49<02:22,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.220735785953178e-06, 'epoch': 3.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1541/1995 [06:52<01:46,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.086956521739132e-06, 'epoch': 3.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1550/1995 [06:54<01:55,  3.85it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1550\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1550/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.953177257525084e-06, 'epoch': 3.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1550/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1550/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1550/special_tokens_map.json\n",
      " 78%|███████▊  | 1560/1995 [06:58<01:59,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.819397993311037e-06, 'epoch': 3.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 1570/1995 [07:00<01:39,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.68561872909699e-06, 'epoch': 3.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 1580/1995 [07:03<01:37,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.551839464882943e-06, 'epoch': 3.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 1590/1995 [07:05<01:35,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.418060200668896e-06, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1596/1995 [07:07<01:39,  4.01it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Answer, text, __index_level_0__. If Answer, text, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 355\n",
      "  Batch size = 8\n",
      "\n",
      " 80%|████████  | 1596/1995 [07:09<01:39,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3432031042981407e-09, 'eval_runtime': 2.3682, 'eval_samples_per_second': 149.903, 'eval_steps_per_second': 19.002, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1600/1995 [07:10<03:08,  2.10it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1600\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1600/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.28428093645485e-06, 'epoch': 4.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1600/special_tokens_map.json\n",
      " 81%|████████  | 1610/1995 [07:14<01:48,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.150501672240803e-06, 'epoch': 4.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 1620/1995 [07:16<01:30,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 5.016722408026757e-06, 'epoch': 4.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1630/1995 [07:18<01:26,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.882943143812709e-06, 'epoch': 4.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1640/1995 [07:21<01:33,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.749163879598663e-06, 'epoch': 4.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1650/1995 [07:23<01:22,  4.17it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1650\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1650/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.615384615384616e-06, 'epoch': 4.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1650/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1650/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1650/special_tokens_map.json\n",
      " 83%|████████▎ | 1660/1995 [07:27<01:32,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.481605351170569e-06, 'epoch': 4.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 1670/1995 [07:30<01:19,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.347826086956522e-06, 'epoch': 4.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1680/1995 [07:32<01:17,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.214046822742475e-06, 'epoch': 4.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1690/1995 [07:35<01:19,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.080267558528428e-06, 'epoch': 4.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1700/1995 [07:37<01:11,  4.11it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1700\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1700/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.946488294314382e-06, 'epoch': 4.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1700/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1700/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1700/special_tokens_map.json\n",
      " 86%|████████▌ | 1710/1995 [07:41<01:13,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.812709030100335e-06, 'epoch': 4.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1720/1995 [07:43<01:06,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.6789297658862878e-06, 'epoch': 4.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1730/1995 [07:46<01:06,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.5451505016722408e-06, 'epoch': 4.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1740/1995 [07:48<01:02,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.4113712374581942e-06, 'epoch': 4.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1750/1995 [07:51<01:03,  3.85it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1750\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1750/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.2775919732441473e-06, 'epoch': 4.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1750/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1750/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1750/special_tokens_map.json\n",
      " 88%|████████▊ | 1760/1995 [07:55<01:09,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.1438127090301007e-06, 'epoch': 4.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 1770/1995 [07:58<00:58,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.010033444816054e-06, 'epoch': 4.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1780/1995 [08:00<00:53,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.8762541806020068e-06, 'epoch': 4.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 1790/1995 [08:03<00:49,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.74247491638796e-06, 'epoch': 4.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1800/1995 [08:05<00:47,  4.14it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1800\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1800/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.6086956521739132e-06, 'epoch': 4.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1800/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1800/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1800/special_tokens_map.json\n",
      " 91%|█████████ | 1810/1995 [08:09<00:51,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.4749163879598663e-06, 'epoch': 4.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1820/1995 [08:11<00:42,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.3411371237458197e-06, 'epoch': 4.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1830/1995 [08:14<00:47,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.2073578595317727e-06, 'epoch': 4.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1840/1995 [08:17<00:40,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.0735785953177258e-06, 'epoch': 4.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1850/1995 [08:19<00:34,  4.18it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1850\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1850/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.9397993311036792e-06, 'epoch': 4.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1850/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1850/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1850/special_tokens_map.json\n",
      " 93%|█████████▎| 1860/1995 [08:23<00:34,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.8060200668896322e-06, 'epoch': 4.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 1870/1995 [08:25<00:28,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.6722408026755855e-06, 'epoch': 4.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1880/1995 [08:27<00:26,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.5384615384615387e-06, 'epoch': 4.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 1890/1995 [08:30<00:24,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4046822742474917e-06, 'epoch': 4.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1900/1995 [08:32<00:22,  4.19it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1900\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1900/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.270903010033445e-06, 'epoch': 4.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1900/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1900/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1900/special_tokens_map.json\n",
      " 96%|█████████▌| 1910/1995 [08:36<00:25,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.137123745819398e-06, 'epoch': 4.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1920/1995 [08:38<00:18,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.0033444816053512e-06, 'epoch': 4.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1930/1995 [08:41<00:16,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.695652173913044e-07, 'epoch': 4.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1940/1995 [08:44<00:16,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.357859531772576e-07, 'epoch': 4.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1950/1995 [08:46<00:11,  3.98it/s]Saving model checkpoint to ./faq_scope_detection/checkpoint-1950\n",
      "Configuration saved in ./faq_scope_detection/checkpoint-1950/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.020066889632107e-07, 'epoch': 4.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/checkpoint-1950/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/checkpoint-1950/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/checkpoint-1950/special_tokens_map.json\n",
      " 98%|█████████▊| 1960/1995 [08:50<00:09,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.682274247491639e-07, 'epoch': 4.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 1970/1995 [08:52<00:06,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.3444816053511706e-07, 'epoch': 4.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1980/1995 [08:55<00:04,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2.0066889632107025e-07, 'epoch': 4.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1990/1995 [08:58<00:01,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.688963210702342e-08, 'epoch': 4.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1995/1995 [08:59<00:00,  3.95it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Answer, text, __index_level_0__. If Answer, text, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 355\n",
      "  Batch size = 8\n",
      "\n",
      "100%|██████████| 1995/1995 [09:01<00:00,  3.95it/s]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 1995/1995 [09:01<00:00,  3.68it/s]\n",
      "Saving model checkpoint to ./faq_scope_detection\n",
      "Configuration saved in ./faq_scope_detection/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3432031042981407e-09, 'eval_runtime': 2.3013, 'eval_samples_per_second': 154.263, 'eval_steps_per_second': 19.555, 'epoch': 5.0}\n",
      "{'train_runtime': 541.7982, 'train_samples_per_second': 29.457, 'train_steps_per_second': 3.682, 'train_loss': 1.053677208203838e-06, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, DistilBertForSequenceClassification, \\\n",
    "    Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "\n",
    "#set iterations. each iteration will have different out-of-scope training data.\n",
    "iterations = 2\n",
    "\n",
    "for iteration in range (iterations):\n",
    "\n",
    "    #load datasets\n",
    "    faq_data = pd.read_csv('scope_training_datasets/faq_data_batch_1.csv')\n",
    "    faq_data2 = pd.read_csv('scope_training_datasets/faq_data_batch_2.csv')\n",
    "    faq_data3 = pd.read_csv('scope_training_datasets/altered_phung_dataset.csv')\n",
    "    faq_data4 = pd.read_csv('scope_training_datasets/jokes_set.csv')\n",
    "    faq_data5 = pd.read_csv('scope_training_datasets/testdata.csv')\n",
    "\n",
    "    #splits into in scope and out of scope, takes random out of-scope data until total with in scope results to 90-10% split\n",
    "    in_scope_data = faq_data[:685]\n",
    "    out_of_scope_data = faq_data[685:]\n",
    "\n",
    "    num_out_of_scope_for_training = int(80)\n",
    "    out_of_scope_training_data = out_of_scope_data.sample(n=num_out_of_scope_for_training, random_state=42)\n",
    "\n",
    "    in_scope_data2 = faq_data2[:685]\n",
    "    out_of_scope_data2 = faq_data2[685:]\n",
    "\n",
    "    num_out_of_scope_for_training2 = int(80)\n",
    "    out_of_scope_training_data2 = out_of_scope_data2.sample(n=num_out_of_scope_for_training2, random_state=42)\n",
    "\n",
    "    in_scope_data3 = faq_data3[:1027]\n",
    "    out_of_scope_data3 = faq_data3[1027:]\n",
    "\n",
    "    num_out_of_scope_for_training3 = int(100)\n",
    "    out_of_scope_training_data3 = out_of_scope_data3.sample(n=num_out_of_scope_for_training3, random_state=42)\n",
    "\n",
    "    in_scope_data4 = faq_data4[:685]\n",
    "    out_of_scope_data4 = faq_data4[685:]\n",
    "\n",
    "    num_out_of_scope_for_training4 = int(100)\n",
    "    out_of_scope_training_data4 = out_of_scope_data3.sample(n=num_out_of_scope_for_training4, random_state=42)\n",
    "\n",
    "    in_scope_data5 = faq_data5[:41]\n",
    "    out_of_scope_data5 = faq_data5[41:]\n",
    "\n",
    "    #concatenate the in-scope and out-of-scope training data\n",
    "    training_data = pd.concat([in_scope_data, in_scope_data2, out_of_scope_training_data, out_of_scope_training_data2, in_scope_data3, out_of_scope_training_data3, in_scope_data4, out_of_scope_training_data4, in_scope_data5, out_of_scope_data5])\n",
    "\n",
    "    #convert the training data to huggingface dataset format\n",
    "    training_dataset = Dataset.from_pandas(training_data)\n",
    "\n",
    "    #renames columns to suit trainer\n",
    "    training_dataset = training_dataset.rename_column(\"Question\", \"text\")\n",
    "    training_dataset = training_dataset.rename_column(\"Label\", \"label\")\n",
    "\n",
    "    #map labels to 0 for in-scope and 1 for out-of-scope\n",
    "    training_dataset = training_dataset.map(lambda example: {\"label\": 1 if example[\"label\"] == 1 else 0}, \n",
    "                              remove_columns=[\"label\"])\n",
    "\n",
    "    #tokenise training set\n",
    "    tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    tokenized_training_dataset = training_dataset.map(lambda x: tokenizer(x[\"text\"], truncation=True), batched=True)\n",
    "\n",
    "    #split the tokenized training dataset into training and validation sets (10% eval, 90% train)\n",
    "    split_tokenized_training_dataset = tokenized_training_dataset.train_test_split(test_size=0.1)\n",
    "    train_dataset = split_tokenized_training_dataset[\"train\"]\n",
    "    eval_dataset = split_tokenized_training_dataset[\"test\"]\n",
    "\n",
    "    #load model and collater\n",
    "    distilbert_model = DistilBertForSequenceClassification.from_pretrained('./faq_scope_detection', num_labels=2)\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    #training params\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./faq_scope_detection',\n",
    "        num_train_epochs=5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./faq_scope_detection_logs',\n",
    "        logging_steps=10,\n",
    "        save_steps=50,\n",
    "        evaluation_strategy='epoch',\n",
    "        learning_rate=2e-5,\n",
    "    )\n",
    "\n",
    "    #initialise and run trainer\n",
    "    trainer = Trainer(\n",
    "        model=distilbert_model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    #overwrite model\n",
    "    trainer.save_model('./faq_scope_detection')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/justin/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /Users/justin/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
      "loading file tokenizer.json from cache at /Users/justin/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/justin/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/justin/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file ./faq_scope_detection/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"./faq_scope_detection\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ./faq_scope_detection/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at ./faq_scope_detection.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/Users/justin/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 21\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n",
      "  Number of trainable parameters = 66955010\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      " 20%|██        | 3/15 [00:00<00:02,  4.31it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 8\n",
      "\n",
      " 20%|██        | 3/15 [00:00<00:02,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 12.068842887878418, 'eval_runtime': 0.0326, 'eval_samples_per_second': 92.039, 'eval_steps_per_second': 30.68, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [00:01<00:02,  4.24it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 8\n",
      "\n",
      " 40%|████      | 6/15 [00:01<00:02,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 11.965846061706543, 'eval_runtime': 0.0298, 'eval_samples_per_second': 100.556, 'eval_steps_per_second': 33.519, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [00:02<00:01,  4.36it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 8\n",
      "\n",
      " 60%|██████    | 9/15 [00:02<00:01,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 11.787884712219238, 'eval_runtime': 0.031, 'eval_samples_per_second': 96.637, 'eval_steps_per_second': 32.212, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [00:02<00:01,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0354, 'learning_rate': 4.0000000000000003e-07, 'epoch': 3.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [00:02<00:00,  4.40it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 8\n",
      "\n",
      " 80%|████████  | 12/15 [00:02<00:00,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 11.539115905761719, 'eval_runtime': 0.0321, 'eval_samples_per_second': 93.493, 'eval_steps_per_second': 31.164, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:03<00:00,  4.42it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 8\n",
      "\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.42it/s]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.14it/s]\n",
      "Saving model checkpoint to ./faq_scope_detection\n",
      "Configuration saved in ./faq_scope_detection/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 11.224631309509277, 'eval_runtime': 0.0305, 'eval_samples_per_second': 98.473, 'eval_steps_per_second': 32.824, 'epoch': 5.0}\n",
      "{'train_runtime': 3.6155, 'train_samples_per_second': 29.041, 'train_steps_per_second': 4.149, 'train_loss': 4.308137003580729, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./faq_scope_detection/pytorch_model.bin\n",
      "tokenizer config file saved in ./faq_scope_detection/tokenizer_config.json\n",
      "Special tokens file saved in ./faq_scope_detection/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, DistilBertForSequenceClassification, \\\n",
    "    Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "\n",
    "#set iterations. each iteration will have different out-of-scope training data.\n",
    "iterations = 1\n",
    "\n",
    "for iteration in range (iterations):\n",
    "\n",
    "    #load datasets\n",
    "    faq_data = pd.read_csv('scope_training_datasets/swinburneusage.csv')\n",
    "\n",
    "    #splits into in scope and out of scope, takes random out of-scope data until total with in scope results to 90-10% split\n",
    "    in_scope_data = faq_data[:13]\n",
    "    out_of_scope_data = faq_data[13:]\n",
    "\n",
    "\n",
    "    #concatenate the in-scope and out-of-scope training data\n",
    "    training_data = pd.concat([in_scope_data, out_of_scope_data])\n",
    "\n",
    "    #convert the training data to huggingface dataset format\n",
    "    training_dataset = Dataset.from_pandas(training_data)\n",
    "\n",
    "    #renames columns to suit trainer\n",
    "    training_dataset = training_dataset.rename_column(\"Question\", \"text\")\n",
    "    training_dataset = training_dataset.rename_column(\"Label\", \"label\")\n",
    "\n",
    "    #map labels to 0 for in-scope and 1 for out-of-scope\n",
    "    training_dataset = training_dataset.map(lambda example: {\"label\": 1 if example[\"label\"] == 1 else 0}, \n",
    "                              remove_columns=[\"label\"])\n",
    "\n",
    "    #tokenise training set\n",
    "    tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    tokenized_training_dataset = training_dataset.map(lambda x: tokenizer(x[\"text\"], truncation=True), batched=True)\n",
    "\n",
    "    #split the tokenized training dataset into training and validation sets (10% eval, 90% train)\n",
    "    split_tokenized_training_dataset = tokenized_training_dataset.train_test_split(test_size=0.1)\n",
    "    train_dataset = split_tokenized_training_dataset[\"train\"]\n",
    "    eval_dataset = split_tokenized_training_dataset[\"test\"]\n",
    "\n",
    "    #load model and collater\n",
    "    distilbert_model = DistilBertForSequenceClassification.from_pretrained('./faq_scope_detection', num_labels=2)\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    #training params\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./faq_scope_detection',\n",
    "        num_train_epochs=5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./faq_scope_detection_logs',\n",
    "        logging_steps=10,\n",
    "        save_steps=50,\n",
    "        evaluation_strategy='epoch',\n",
    "        learning_rate=2e-5,\n",
    "    )\n",
    "\n",
    "    #initialise and run trainer\n",
    "    trainer = Trainer(\n",
    "        model=distilbert_model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    #overwrite model\n",
    "    trainer.save_model('./faq_scope_detection')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h2 style='font-family:Monocraft'>Model Evaluation Script<h2>\n",
    "    calcs f1 and accuracy using a test dataset and prints. also prints incorrectly labelled questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justin/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "F1 Score: 0.999999994846154\n",
      "torch.Size([0])\n",
      "\n",
      "Inaccurately labeled questions:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, DistilBertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "#load model\n",
    "tokenizer = AutoTokenizer.from_pretrained('./scopeclassifier')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('./scopeclassifier')\n",
    "\n",
    "#load test set\n",
    "test_data = pd.read_csv('scope_training_datasets/testdata.csv')\n",
    "\n",
    "#name columns\n",
    "test_data = test_data.rename(columns={'Question': 'text'})\n",
    "test_data = test_data[:1000]\n",
    "#tokenise dataset\n",
    "tokenized_test_dataset = tokenizer(test_data['text'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "#functions for f1 and acc\n",
    "def calculate_accuracy(preds, labels):\n",
    "    correct = (preds == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    return correct / total\n",
    "\n",
    "def calculate_f1_score(preds, labels):\n",
    "    tp = ((preds == 1) & (labels == 1)).sum().item()\n",
    "    tn = ((preds == 0) & (labels == 0)).sum().item()\n",
    "    fp = ((preds == 1) & (labels == 0)).sum().item()\n",
    "    fn = ((preds == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "\n",
    "    return f1\n",
    "\n",
    "#generate predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokenized_test_dataset)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "#get labels\n",
    "labels = torch.tensor(test_data['Label'].tolist())\n",
    "\n",
    "#calc f1 and acc and print scores\n",
    "accuracy = calculate_accuracy(predictions, labels)\n",
    "f1_score = calculate_f1_score(predictions, labels)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "#print failures\n",
    "incorrect_idx = (predictions != labels).nonzero().squeeze()\n",
    "incorrect_predictions = predictions[incorrect_idx].tolist()\n",
    "true_labels = labels[incorrect_idx].tolist()\n",
    "incorrect_questions = test_data.iloc[incorrect_idx]['text'].tolist()\n",
    "print(incorrect_idx.size())\n",
    "\n",
    "print(\"\\nInaccurately labeled questions:\")\n",
    "for q, p, l in zip(incorrect_questions, incorrect_predictions, true_labels):\n",
    "    print(f\"Question: {q}\")\n",
    "    print(f\"Predicted label: {p}\")\n",
    "    print(f\"True label: {l}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
